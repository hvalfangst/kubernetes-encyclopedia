apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: log-collector # Name of the DaemonSet
  labels:
    app: log-collector
    component: logging
    tier: infrastructure
spec:
  selector:
    matchLabels:
      app: log-collector # Must match template labels
  
  # Update strategy for DaemonSet
  updateStrategy:
    type: RollingUpdate # Update pods gradually
    rollingUpdate:
      maxUnavailable: 1 # At most 1 pod unavailable per node during update
      maxSurge: 0 # Cannot exceed desired number (one per node)
  
  # Pod template
  template:
    metadata:
      labels:
        app: log-collector
        component: logging
        tier: infrastructure
    spec:
      # Host network and privileges for system-level access
      hostNetwork: false # Set to true if need host networking
      hostPID: false # Set to true if need access to host processes
      
      # Service account for proper permissions
      serviceAccountName: log-collector-sa
      
      # Tolerations to run on all nodes (including control plane)
      tolerations:
      - key: node-role.kubernetes.io/control-plane
        operator: Exists
        effect: NoSchedule
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
      - key: node.kubernetes.io/disk-pressure
        operator: Exists
        effect: NoSchedule
      - key: node.kubernetes.io/memory-pressure
        operator: Exists
        effect: NoSchedule
      - key: node.kubernetes.io/unreachable
        operator: Exists
        effect: NoExecute
        tolerationSeconds: 300
      
      # Node selector (optional - run on specific nodes)
      # nodeSelector:
      #   kubernetes.io/os: linux
      
      containers:
      - name: log-collector
        image: fluent/fluentd:v1.16 # Log collection and forwarding
        
        # Environment variables
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: FLUENTD_CONF
          value: "fluent.conf"
        - name: FLUENTD_OPT
          value: ""
          
        # Resource limits for DaemonSet pods
        resources:
          requests:
            memory: "200Mi"
            cpu: "100m"
          limits:
            memory: "400Mi"
            cpu: "200m"
            
        # Volume mounts for log collection
        volumeMounts:
        - name: varlog # Host /var/log directory
          mountPath: /var/log
          readOnly: true
        - name: dockercontainers # Docker container logs
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: config # Fluentd configuration
          mountPath: /fluentd/etc
        - name: buffer # Buffer for log processing
          mountPath: /var/buffer
          
        # Health checks
        livenessProbe:
          httpGet:
            path: /metrics
            port: 24231
          initialDelaySeconds: 60
          periodSeconds: 60
        readinessProbe:
          httpGet:
            path: /metrics
            port: 24231
          initialDelaySeconds: 10
          periodSeconds: 30
          
        # Security context
        securityContext:
          runAsUser: 0 # Run as root for log access
          privileged: false
          readOnlyRootFilesystem: false
          allowPrivilegeEscalation: false
          
        # Ports
        ports:
        - containerPort: 24231
          name: metrics
          protocol: TCP
        - containerPort: 24224
          name: forward
          protocol: TCP
          
      # Volumes for host system access
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
          type: Directory
      - name: dockercontainers
        hostPath:
          path: /var/lib/docker/containers
          type: DirectoryOrCreate
      - name: config
        configMap:
          name: fluentd-config
      - name: buffer
        emptyDir:
          sizeLimit: 2Gi
          
      # Priority class for system-critical workload
      priorityClassName: system-node-critical
      
      # DNS policy
      dnsPolicy: ClusterFirst
      
      # Termination grace period
      terminationGracePeriodSeconds: 30
---
# ConfigMap for Fluentd configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  labels:
    app: log-collector
data:
  fluent.conf: |
    # Input: Read from Docker container logs
    <source>
      @type tail
      path /var/log/containers/*.log
      pos_file /var/buffer/fluentd-docker.log.pos
      tag kubernetes.*
      read_from_head true
      <parse>
        @type multi_format
        <pattern>
          format json
          time_key time
          time_format %Y-%m-%dT%H:%M:%S.%NZ
        </pattern>
        <pattern>
          format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
          time_format %Y-%m-%dT%H:%M:%S.%N%:z
        </pattern>
      </parse>
    </source>
    
    # Input: Read from systemd journal
    <source>
      @type systemd
      tag systemd
      path /var/log/journal
      <storage>
        @type local
        persistent true
        path /var/buffer/systemd.pos
      </storage>
      <entry>
        fields_strip_underscores true
        fields_lowercase true
      </entry>
    </source>
    
    # Filter: Add Kubernetes metadata
    <filter kubernetes.**>
      @type kubernetes_metadata
    </filter>
    
    # Filter: Add node information
    <filter **>
      @type record_transformer
      <record>
        node_name "#{ENV['NODE_NAME']}"
        pod_name "#{ENV['POD_NAME']}"
        pod_namespace "#{ENV['POD_NAMESPACE']}"
      </record>
    </filter>
    
    # Output: Forward to log aggregator (example)
    <match **>
      @type forward
      <server>
        name log-aggregator
        host log-aggregator-service
        port 24224
      </server>
      <buffer>
        @type file
        path /var/buffer/forward
        flush_mode interval
        flush_interval 30s
        chunk_limit_size 2M
        queue_limit_length 8
        retry_max_interval 30
        retry_forever true
      </buffer>
    </match>
    
    # Metrics endpoint
    <source>
      @type monitor_agent
      bind 0.0.0.0
      port 24231
      tag fluentd.monitor.metrics
    </source>
---
# ServiceAccount for the DaemonSet
apiVersion: v1
kind: ServiceAccount
metadata:
  name: log-collector-sa
  labels:
    app: log-collector
---
# ClusterRole for log collection permissions
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: log-collector-role
  labels:
    app: log-collector
rules:
- apiGroups: [""]
  resources: ["pods", "namespaces", "nodes"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps"]
  resources: ["replicasets"]
  verbs: ["get", "list", "watch"]
---
# ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: log-collector-binding
  labels:
    app: log-collector
subjects:
- kind: ServiceAccount
  name: log-collector-sa
  namespace: default
roleRef:
  kind: ClusterRole
  name: log-collector-role
  apiGroup: rbac.authorization.k8s.io
---
# Monitoring DaemonSet example (node-exporter)
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
  labels:
    app: node-exporter
    component: monitoring
spec:
  selector:
    matchLabels:
      app: node-exporter
  template:
    metadata:
      labels:
        app: node-exporter
        component: monitoring
    spec:
      # Host network for accurate metrics collection
      hostNetwork: true
      hostPID: true
      
      # Tolerations for running on all nodes
      tolerations:
      - operator: Exists
        effect: NoSchedule
      
      containers:
      - name: node-exporter
        image: prom/node-exporter:v1.6.1
        args:
        - --path.procfs=/host/proc
        - --path.sysfs=/host/sys
        - --path.rootfs=/host/root
        - --collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)
        - --web.listen-address=:9100
        
        ports:
        - containerPort: 9100
          name: metrics
          protocol: TCP
          
        resources:
          requests:
            memory: "50Mi"
            cpu: "50m"
          limits:
            memory: "100Mi"
            cpu: "100m"
            
        volumeMounts:
        - name: proc
          mountPath: /host/proc
          readOnly: true
        - name: sys
          mountPath: /host/sys
          readOnly: true
        - name: root
          mountPath: /host/root
          readOnly: true
          
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534 # nobody user
          
        livenessProbe:
          httpGet:
            path: /metrics
            port: 9100
          initialDelaySeconds: 30
          periodSeconds: 30
          
      volumes:
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys
      - name: root
        hostPath:
          path: /
---
# Service for node-exporter metrics
apiVersion: v1
kind: Service
metadata:
  name: node-exporter-service
  labels:
    app: node-exporter
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9100"
spec:
  type: ClusterIP
  clusterIP: None # Headless service
  selector:
    app: node-exporter
  ports:
  - name: metrics
    port: 9100
    targetPort: 9100
    protocol: TCP